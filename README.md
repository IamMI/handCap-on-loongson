# ðŸ¤— handCap-on-loongson

## Motivation
We hope to build a frame to complete **Human Gesture Dectection** through `Edge -> Server -> Client`, which may be useful in VR. In our work, we use *Loongson development board* at edge and create an *Aliyun server* at cloud.

## Demo
<video src="demo.mp4" controls width="600">
  Your browser does not support the video tag.
</video>


## Our team
| **Idea**                               |  **Date**   | **Authors**                         |
|----------------------------------------|------------|--------------------------------------|
| Record videos and detect human gestures |   2025-07-01 |  Zhixuan You, Zhanhang LÃ¼, Jiayi Huang |

## Structure of our work
You should follow our tutorial step by step:
- Cloud: [Website](https://github.com/IamMI/handCap-aliyun)
- Edge: [Website](https://github.com/IamMI/handCap-edge)
- Client: [Website](https://github.com/IamMI/handCap-client)

## TODO
- [ ] Upload demo video

